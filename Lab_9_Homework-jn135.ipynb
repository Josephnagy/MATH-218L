{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Make a copy of this notebook (File menu -> Make a Copy...)\n",
    "\n",
    "### Homework Question 1\n",
    "Consider the same situation as in Question 15 from the lab, but on a pentagon instead of a square. That is, there are five corners instead of four. Show that the corresponding Markov chain is not periodic, and that its transition matrix is regular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not Periodic ####\n",
    "A state in a Markov chain has period k if any return to it must occur in multiples of k steps. With a pentagon, going in a full circle to return to the original point produces an odd number of steps. On the other hand, going forward one step and backward one step (an even number of steps) will also return you to the original point. Therefore, any return to the original point does not occur in multiples of k steps.\n",
    "\n",
    "#### Regular ####\n",
    "Over time, there is a chance that you can be at any corner of the pentagon (since returning to a point doesn't depend on cycles). A^n contains non-zero entries for some n, as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.5 0.  0.  0.5]\n",
      " [0.5 0.  0.5 0.  0. ]\n",
      " [0.  0.5 0.  0.5 0. ]\n",
      " [0.  0.  0.5 0.  0.5]\n",
      " [0.5 0.  0.  0.5 0. ]]\n",
      "[[0.5  0.   0.25 0.25 0.  ]\n",
      " [0.   0.5  0.   0.25 0.25]\n",
      " [0.25 0.   0.5  0.   0.25]\n",
      " [0.25 0.25 0.   0.5  0.  ]\n",
      " [0.   0.25 0.25 0.   0.5 ]]\n",
      "[[0.    0.375 0.125 0.125 0.375]\n",
      " [0.375 0.    0.375 0.125 0.125]\n",
      " [0.125 0.375 0.    0.375 0.125]\n",
      " [0.125 0.125 0.375 0.    0.375]\n",
      " [0.375 0.125 0.125 0.375 0.   ]]\n",
      "[[0.375  0.0625 0.25   0.25   0.0625]\n",
      " [0.0625 0.375  0.0625 0.25   0.25  ]\n",
      " [0.25   0.0625 0.375  0.0625 0.25  ]\n",
      " [0.25   0.25   0.0625 0.375  0.0625]\n",
      " [0.0625 0.25   0.25   0.0625 0.375 ]]\n",
      "[[0.0625  0.3125  0.15625 0.15625 0.3125 ]\n",
      " [0.3125  0.0625  0.3125  0.15625 0.15625]\n",
      " [0.15625 0.3125  0.0625  0.3125  0.15625]\n",
      " [0.15625 0.15625 0.3125  0.0625  0.3125 ]\n",
      " [0.3125  0.15625 0.15625 0.3125  0.0625 ]]\n",
      "[[0.3125   0.109375 0.234375 0.234375 0.109375]\n",
      " [0.109375 0.3125   0.109375 0.234375 0.234375]\n",
      " [0.234375 0.109375 0.3125   0.109375 0.234375]\n",
      " [0.234375 0.234375 0.109375 0.3125   0.109375]\n",
      " [0.109375 0.234375 0.234375 0.109375 0.3125  ]]\n",
      "[[0.109375  0.2734375 0.171875  0.171875  0.2734375]\n",
      " [0.2734375 0.109375  0.2734375 0.171875  0.171875 ]\n",
      " [0.171875  0.2734375 0.109375  0.2734375 0.171875 ]\n",
      " [0.171875  0.171875  0.2734375 0.109375  0.2734375]\n",
      " [0.2734375 0.171875  0.171875  0.2734375 0.109375 ]]\n",
      "[[0.2734375  0.140625   0.22265625 0.22265625 0.140625  ]\n",
      " [0.140625   0.2734375  0.140625   0.22265625 0.22265625]\n",
      " [0.22265625 0.140625   0.2734375  0.140625   0.22265625]\n",
      " [0.22265625 0.22265625 0.140625   0.2734375  0.140625  ]\n",
      " [0.140625   0.22265625 0.22265625 0.140625   0.2734375 ]]\n",
      "[[0.140625   0.24804688 0.18164062 0.18164062 0.24804688]\n",
      " [0.24804688 0.140625   0.24804688 0.18164062 0.18164062]\n",
      " [0.18164062 0.24804688 0.140625   0.24804688 0.18164062]\n",
      " [0.18164062 0.18164062 0.24804688 0.140625   0.24804688]\n",
      " [0.24804688 0.18164062 0.18164062 0.24804688 0.140625  ]]\n",
      "[[0.24804688 0.16113281 0.21484375 0.21484375 0.16113281]\n",
      " [0.16113281 0.24804688 0.16113281 0.21484375 0.21484375]\n",
      " [0.21484375 0.16113281 0.24804688 0.16113281 0.21484375]\n",
      " [0.21484375 0.21484375 0.16113281 0.24804688 0.16113281]\n",
      " [0.16113281 0.21484375 0.21484375 0.16113281 0.24804688]]\n",
      "[[0.16113281 0.23144531 0.18798828 0.18798828 0.23144531]\n",
      " [0.23144531 0.16113281 0.23144531 0.18798828 0.18798828]\n",
      " [0.18798828 0.23144531 0.16113281 0.23144531 0.18798828]\n",
      " [0.18798828 0.18798828 0.23144531 0.16113281 0.23144531]\n",
      " [0.23144531 0.18798828 0.18798828 0.23144531 0.16113281]]\n",
      "[[0.23144531 0.17456055 0.2097168  0.2097168  0.17456055]\n",
      " [0.17456055 0.23144531 0.17456055 0.2097168  0.2097168 ]\n",
      " [0.2097168  0.17456055 0.23144531 0.17456055 0.2097168 ]\n",
      " [0.2097168  0.2097168  0.17456055 0.23144531 0.17456055]\n",
      " [0.17456055 0.2097168  0.2097168  0.17456055 0.23144531]]\n",
      "[[0.17456055 0.22058105 0.19213867 0.19213867 0.22058105]\n",
      " [0.22058105 0.17456055 0.22058105 0.19213867 0.19213867]\n",
      " [0.19213867 0.22058105 0.17456055 0.22058105 0.19213867]\n",
      " [0.19213867 0.19213867 0.22058105 0.17456055 0.22058105]\n",
      " [0.22058105 0.19213867 0.19213867 0.22058105 0.17456055]]\n",
      "[[0.22058105 0.18334961 0.20635986 0.20635986 0.18334961]\n",
      " [0.18334961 0.22058105 0.18334961 0.20635986 0.20635986]\n",
      " [0.20635986 0.18334961 0.22058105 0.18334961 0.20635986]\n",
      " [0.20635986 0.20635986 0.18334961 0.22058105 0.18334961]\n",
      " [0.18334961 0.20635986 0.20635986 0.18334961 0.22058105]]\n",
      "[[0.18334961 0.21347046 0.19485474 0.19485474 0.21347046]\n",
      " [0.21347046 0.18334961 0.21347046 0.19485474 0.19485474]\n",
      " [0.19485474 0.21347046 0.18334961 0.21347046 0.19485474]\n",
      " [0.19485474 0.19485474 0.21347046 0.18334961 0.21347046]\n",
      " [0.21347046 0.19485474 0.19485474 0.21347046 0.18334961]]\n",
      "[[0.21347046 0.18910217 0.2041626  0.2041626  0.18910217]\n",
      " [0.18910217 0.21347046 0.18910217 0.2041626  0.2041626 ]\n",
      " [0.2041626  0.18910217 0.21347046 0.18910217 0.2041626 ]\n",
      " [0.2041626  0.2041626  0.18910217 0.21347046 0.18910217]\n",
      " [0.18910217 0.2041626  0.2041626  0.18910217 0.21347046]]\n",
      "[[0.18910217 0.20881653 0.19663239 0.19663239 0.20881653]\n",
      " [0.20881653 0.18910217 0.20881653 0.19663239 0.19663239]\n",
      " [0.19663239 0.20881653 0.18910217 0.20881653 0.19663239]\n",
      " [0.19663239 0.19663239 0.20881653 0.18910217 0.20881653]\n",
      " [0.20881653 0.19663239 0.19663239 0.20881653 0.18910217]]\n",
      "[[0.20881653 0.19286728 0.20272446 0.20272446 0.19286728]\n",
      " [0.19286728 0.20881653 0.19286728 0.20272446 0.20272446]\n",
      " [0.20272446 0.19286728 0.20881653 0.19286728 0.20272446]\n",
      " [0.20272446 0.20272446 0.19286728 0.20881653 0.19286728]\n",
      " [0.19286728 0.20272446 0.20272446 0.19286728 0.20881653]]\n",
      "[[0.19286728 0.20577049 0.19779587 0.19779587 0.20577049]\n",
      " [0.20577049 0.19286728 0.20577049 0.19779587 0.19779587]\n",
      " [0.19779587 0.20577049 0.19286728 0.20577049 0.19779587]\n",
      " [0.19779587 0.19779587 0.20577049 0.19286728 0.20577049]\n",
      " [0.20577049 0.19779587 0.19779587 0.20577049 0.19286728]]\n",
      "[[0.20577049 0.19533157 0.20178318 0.20178318 0.19533157]\n",
      " [0.19533157 0.20577049 0.19533157 0.20178318 0.20178318]\n",
      " [0.20178318 0.19533157 0.20577049 0.19533157 0.20178318]\n",
      " [0.20178318 0.20178318 0.19533157 0.20577049 0.19533157]\n",
      " [0.19533157 0.20178318 0.20178318 0.19533157 0.20577049]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pentagon = np.array([[0,0.5,0,0,0.5],[0.5,0,0.5,0,0],[0,0.5,0,0.5,0],[0,0,0.5,0,0.5],[0.5,0,0,0.5,0]])\n",
    "for i in range(1,21):\n",
    "    print(np.linalg.matrix_power(pentagon,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework Question 2\n",
    "Consider a Markov chain with transition matrix given by the following code:\n",
    "  ```python\n",
    "  A= np.array([\n",
    "               [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.5   ,  0.25  ],\n",
    "               [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.5   ,  0.75  ],\n",
    "               [ 0.5   ,  0.3333,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ],\n",
    "               [ 0.25  ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ],\n",
    "               [ 0.25  ,  0.6667,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ],\n",
    "               [ 0.    ,  0.    ,  0.3333,  0.5   ,  0.75  ,  0.    ,  0.    ],\n",
    "               [ 0.    ,  0.    ,  0.6667,  0.5   ,  0.25  ,  0.    ,  0.    ]])\n",
    "   ```\n",
    "  \n",
    "1. Draw a state space diagram for this chain (use [this link](https://graphonline.ru/en/)). If you're having trouble putting the nodes and arrows in sensible places, you may want to do the rest of this question first.<br><br>\n",
    "1. Show that this chain is periodic. What is the period?<br><br>\n",
    "1. By again considering powers of this matrix, show that the seven nodes divide into three *cyclic classes*. That is, show that there are three subsets of nodes, $A$, $B$, and $C$, each with the property 'if we start at a node in a given class, we can only return to the class $p$ steps later, where $p$ is the period of the chain'. Numbering the nodes from 1 to 7, which nodes are in each cyclic class?<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 ###\n",
    "See GradeScope Attachment\n",
    "### Question 2 ###\n",
    "The period is 3. If we observe A^n, the transition matrix has zero entries over time, indicating that there are some vertices that we cannot return to from a given vertex. This is because to return to some vertices, it takes 3K steps. If we focus on one node, A, for example, we notice that only after every three powers does the probability for getting to A from A become positive. In other words, it always takes multiples of three steps for A to return to itself.\n",
    "\n",
    "### Question 3 ###\n",
    "If nodes A-G are numbered 1-7, we can say that nodes 1 and 2 belong to cyclic class A, 3-5 belong to B, and 6 and 7 belong to C. If we look at every third matrix power, that's the only time that for a given node, the probability of getting to the other nodes in its class is positive. In other words, given that we start at node 1, after the third matrix power, it is possible to reach node 1 or 2 (since the probability is positive), and so the nodes are in the same cyclic class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.    0.    0.    0.    0.5   0.25 ]\n",
      " [0.    0.    0.    0.    0.    0.5   0.75 ]\n",
      " [0.5   0.333 0.    0.    0.    0.    0.   ]\n",
      " [0.25  0.    0.    0.    0.    0.    0.   ]\n",
      " [0.25  0.667 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.333 0.5   0.75  0.    0.   ]\n",
      " [0.    0.    0.667 0.5   0.25  0.    0.   ]]\n",
      "[[0.    0.    0.333 0.375 0.438 0.    0.   ]\n",
      " [0.    0.    0.667 0.625 0.562 0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.417 0.375]\n",
      " [0.    0.    0.    0.    0.    0.125 0.062]\n",
      " [0.    0.    0.    0.    0.    0.458 0.563]\n",
      " [0.479 0.611 0.    0.    0.    0.    0.   ]\n",
      " [0.521 0.389 0.    0.    0.    0.    0.   ]]\n",
      "[[0.37  0.403 0.    0.    0.    0.    0.   ]\n",
      " [0.63  0.597 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.389 0.396 0.406 0.    0.   ]\n",
      " [0.    0.    0.083 0.094 0.109 0.    0.   ]\n",
      " [0.    0.    0.528 0.51  0.484 0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.545 0.578]\n",
      " [0.    0.    0.    0.    0.    0.455 0.422]]\n",
      "[[0.    0.    0.    0.    0.    0.386 0.395]\n",
      " [0.    0.    0.    0.    0.    0.614 0.605]\n",
      " [0.395 0.4   0.    0.    0.    0.    0.   ]\n",
      " [0.092 0.101 0.    0.    0.    0.    0.   ]\n",
      " [0.513 0.499 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.567 0.562 0.553 0.    0.   ]\n",
      " [0.    0.    0.433 0.438 0.447 0.    0.   ]]\n",
      "[[0.    0.    0.392 0.39  0.388 0.    0.   ]\n",
      " [0.    0.    0.608 0.61  0.612 0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.398 0.399]\n",
      " [0.    0.    0.    0.    0.    0.097 0.099]\n",
      " [0.    0.    0.    0.    0.    0.506 0.502]\n",
      " [0.562 0.558 0.    0.    0.    0.    0.   ]\n",
      " [0.438 0.442 0.    0.    0.    0.    0.   ]]\n",
      "[[0.391 0.389 0.    0.    0.    0.    0.   ]\n",
      " [0.609 0.611 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.399 0.398 0.398 0.    0.   ]\n",
      " [0.    0.    0.098 0.098 0.097 0.    0.   ]\n",
      " [0.    0.    0.503 0.504 0.505 0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.56  0.559]\n",
      " [0.    0.    0.    0.    0.    0.44  0.441]]\n",
      "[[0.    0.    0.    0.    0.    0.39  0.39 ]\n",
      " [0.    0.    0.    0.    0.    0.61  0.61 ]\n",
      " [0.398 0.398 0.    0.    0.    0.    0.   ]\n",
      " [0.098 0.097 0.    0.    0.    0.    0.   ]\n",
      " [0.504 0.504 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.559 0.56  0.56  0.    0.   ]\n",
      " [0.    0.    0.441 0.44  0.44  0.    0.   ]]\n",
      "[[0.    0.    0.39  0.39  0.39  0.    0.   ]\n",
      " [0.    0.    0.61  0.61  0.61  0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.398 0.398]\n",
      " [0.    0.    0.    0.    0.    0.098 0.097]\n",
      " [0.    0.    0.    0.    0.    0.504 0.504]\n",
      " [0.56  0.56  0.    0.    0.    0.    0.   ]\n",
      " [0.44  0.44  0.    0.    0.    0.    0.   ]]\n",
      "[[0.39  0.39  0.    0.    0.    0.    0.   ]\n",
      " [0.61  0.61  0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.398 0.398 0.398 0.    0.   ]\n",
      " [0.    0.    0.097 0.097 0.097 0.    0.   ]\n",
      " [0.    0.    0.504 0.504 0.504 0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.56  0.56 ]\n",
      " [0.    0.    0.    0.    0.    0.44  0.44 ]]\n",
      "[[0.    0.    0.    0.    0.    0.39  0.39 ]\n",
      " [0.    0.    0.    0.    0.    0.61  0.61 ]\n",
      " [0.398 0.398 0.    0.    0.    0.    0.   ]\n",
      " [0.097 0.097 0.    0.    0.    0.    0.   ]\n",
      " [0.504 0.504 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.56  0.56  0.56  0.    0.   ]\n",
      " [0.    0.    0.44  0.44  0.44  0.    0.   ]]\n",
      "[[0.    0.    0.39  0.39  0.39  0.    0.   ]\n",
      " [0.    0.    0.61  0.61  0.61  0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.398 0.398]\n",
      " [0.    0.    0.    0.    0.    0.097 0.097]\n",
      " [0.    0.    0.    0.    0.    0.504 0.504]\n",
      " [0.56  0.56  0.    0.    0.    0.    0.   ]\n",
      " [0.44  0.44  0.    0.    0.    0.    0.   ]]\n",
      "[[0.39  0.39  0.    0.    0.    0.    0.   ]\n",
      " [0.61  0.61  0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.398 0.398 0.398 0.    0.   ]\n",
      " [0.    0.    0.097 0.097 0.097 0.    0.   ]\n",
      " [0.    0.    0.504 0.504 0.504 0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.56  0.56 ]\n",
      " [0.    0.    0.    0.    0.    0.44  0.44 ]]\n",
      "[[0.    0.    0.    0.    0.    0.39  0.39 ]\n",
      " [0.    0.    0.    0.    0.    0.61  0.61 ]\n",
      " [0.398 0.398 0.    0.    0.    0.    0.   ]\n",
      " [0.097 0.097 0.    0.    0.    0.    0.   ]\n",
      " [0.504 0.504 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.56  0.56  0.56  0.    0.   ]\n",
      " [0.    0.    0.44  0.44  0.44  0.    0.   ]]\n",
      "[[0.    0.    0.39  0.39  0.39  0.    0.   ]\n",
      " [0.    0.    0.61  0.61  0.61  0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.398 0.398]\n",
      " [0.    0.    0.    0.    0.    0.097 0.097]\n",
      " [0.    0.    0.    0.    0.    0.504 0.504]\n",
      " [0.56  0.56  0.    0.    0.    0.    0.   ]\n",
      " [0.44  0.44  0.    0.    0.    0.    0.   ]]\n",
      "[[0.39  0.39  0.    0.    0.    0.    0.   ]\n",
      " [0.61  0.61  0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.398 0.398 0.398 0.    0.   ]\n",
      " [0.    0.    0.097 0.097 0.097 0.    0.   ]\n",
      " [0.    0.    0.504 0.504 0.504 0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.56  0.56 ]\n",
      " [0.    0.    0.    0.    0.    0.44  0.44 ]]\n",
      "[[0.    0.    0.    0.    0.    0.39  0.39 ]\n",
      " [0.    0.    0.    0.    0.    0.61  0.61 ]\n",
      " [0.398 0.398 0.    0.    0.    0.    0.   ]\n",
      " [0.097 0.097 0.    0.    0.    0.    0.   ]\n",
      " [0.504 0.504 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.56  0.56  0.56  0.    0.   ]\n",
      " [0.    0.    0.44  0.44  0.44  0.    0.   ]]\n",
      "[[0.    0.    0.39  0.39  0.39  0.    0.   ]\n",
      " [0.    0.    0.61  0.61  0.61  0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.398 0.398]\n",
      " [0.    0.    0.    0.    0.    0.097 0.097]\n",
      " [0.    0.    0.    0.    0.    0.504 0.504]\n",
      " [0.56  0.56  0.    0.    0.    0.    0.   ]\n",
      " [0.44  0.44  0.    0.    0.    0.    0.   ]]\n",
      "[[0.39  0.39  0.    0.    0.    0.    0.   ]\n",
      " [0.61  0.61  0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.398 0.398 0.398 0.    0.   ]\n",
      " [0.    0.    0.097 0.097 0.097 0.    0.   ]\n",
      " [0.    0.    0.504 0.504 0.504 0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.56  0.56 ]\n",
      " [0.    0.    0.    0.    0.    0.44  0.44 ]]\n",
      "[[0.    0.    0.    0.    0.    0.39  0.39 ]\n",
      " [0.    0.    0.    0.    0.    0.61  0.61 ]\n",
      " [0.398 0.398 0.    0.    0.    0.    0.   ]\n",
      " [0.097 0.097 0.    0.    0.    0.    0.   ]\n",
      " [0.504 0.504 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.56  0.56  0.56  0.    0.   ]\n",
      " [0.    0.    0.44  0.44  0.44  0.    0.   ]]\n",
      "[[0.    0.    0.39  0.39  0.39  0.    0.   ]\n",
      " [0.    0.    0.61  0.61  0.61  0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.398 0.398]\n",
      " [0.    0.    0.    0.    0.    0.097 0.097]\n",
      " [0.    0.    0.    0.    0.    0.504 0.504]\n",
      " [0.56  0.56  0.    0.    0.    0.    0.   ]\n",
      " [0.44  0.44  0.    0.    0.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "A= np.array([\n",
    "               [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.5   ,  0.25  ],\n",
    "               [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.5   ,  0.75  ],\n",
    "               [ 0.5   ,  0.3333,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ],\n",
    "               [ 0.25  ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ],\n",
    "               [ 0.25  ,  0.6667,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ],\n",
    "               [ 0.    ,  0.    ,  0.3333,  0.5   ,  0.75  ,  0.    ,  0.    ],\n",
    "               [ 0.    ,  0.    ,  0.6667,  0.5   ,  0.25  ,  0.    ,  0.    ]])\n",
    "np.set_printoptions(precision=3)\n",
    "for i in range(1,21):\n",
    "    print(np.linalg.matrix_power(A,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework Question 3\n",
    "\n",
    "For this question, you will write code that generates sensible random words that are (mostly) pronounceable in English. You will do this by creating a Markov chain whose nodes are letters in English words, and whose transition probabilities are given by analyzing a large set of existing English words.<br><br>\n",
    "\n",
    "1. You will find a set of approximately 275,000 English words in the file *data/en.txt*. We will use this to figure out what the probability of a letter occuring in a word is, given the previous letter. For example, if the current letter is 'q', the next letter is 'u' with very high probability. Generate the transition matrix between all 26 states (a.k.a. English letters). Here are some code snippets that might help: \n",
    "```python\n",
    "      # This opens the file and prints every line.\n",
    "      f = open('data/en.txt')\n",
    "      for word in f:\n",
    "         print(word)\n",
    "\n",
    "      # After you're done with a file, close it:\n",
    "      f.close()\n",
    "\n",
    "      # Each line has an extra character at the end (the endline character). The following code strips it:\n",
    "      word = word.rstrip()\n",
    "\n",
    "      # Strings can be accessed like one-dimensional arrays:\n",
    "      for i in len(word):\n",
    "         print(word[i])\n",
    "\n",
    "      # The following function will return a number correponding to the letter input.\n",
    "      # e.g. testletter('a') will return 0, and testletter('z') will return 25\n",
    "      import string\n",
    "      def let2num(letter):\n",
    "          dictionary = {letter: index for index, letter in enumerate(string.ascii_lowercase)}\n",
    "          return dictionary[letter]\n",
    "```\n",
    "After you've written your code, check the probabilities of different letters following 'q'. This is a good indicator that your code is correct!<br><br>\n",
    "1. Since this is a large matrix, it would not be efficient to use our row-reduction code to find its eigenvalues and eigenvectors. Instead, we use a NumPy built-in function. By investigating the *np.linalg.eig(A)* function using its documentation, find the eigenvector corresponding to the eigenvalue 1 for your transition matrix. Scale it to ensure that its sum is 1!\n",
    "> **Note: In general, eigenvalues and eigenvectors may be complex (i.e. contain numbers of the form $a+bi$, where $i=\\sqrt{-1}$). The correct eigenvector here has no complex entries. Nonetheless, NumPy will represent the vector using its complex data type. After you're sure you have the right vector, you can cast it to real numbers by using `np.real(v)`.**\n",
    "1. Explain why the entries of this eigenvector should be very close to the frequencies of each letter in the word set.<br><br>\n",
    "1. Write code to check that this is indeed the case.<br><br>\n",
    "1. What is the probability that the letter following 'q' is 'u'? Find some words in the list for which a letter other than 'u' follows a 'q'.<br><br>\n",
    "1. Lastly, write a *namegen(n)* function that generates words of length $n$ using your transition matrix. You may find the following code snippets helpful:\n",
    "```python\n",
    "      # This returns a string containing all lowercase letters:\n",
    "      import string\n",
    "      string.ascii_lowercase\n",
    "\n",
    "      # This returns a random number between 0 and 25, with probability distribution given by the vector v:\n",
    "      np.random.choice(26,p=v)\n",
    "\n",
    "      # You can add a letter to string as follows:\n",
    "      mystring = 'co'\n",
    "      mystring += 'w'\n",
    "      mystring\n",
    "```\n",
    "\n",
    "Test out your code by generating words of different lengths. Are most of them pronounceable? Explain why they are not all pronounceable. \n",
    "  \n",
    "  \n",
    "**Extra Credit** Write down a few ideas that would increase the likelihood of pronounceable randomly generated words. Implement them in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function will return a number correponding to the letter input.\n",
    "# e.g. testletter('a') will return 0, and testletter('z') will return 25\n",
    "import string\n",
    "def let2num(letter):\n",
    "    dictionary = {letter: index for index, letter in enumerate(string.ascii_lowercase)}\n",
    "    return dictionary[letter]\n",
    "\n",
    "#create freq = array to count frequencies of letters; rows = letter we're on\n",
    "#cols = frequency of succeeding letter\n",
    "#create prob = matrix of probabilities where rows is current letter and columns is succeeding\n",
    "freq = np.zeros((26,26))\n",
    "prob = np.zeros_like(freq)\n",
    "f = open('data/en.txt')\n",
    "\n",
    "#iterate through each word, iterate through each character, count frequencies of letters appearing\n",
    "#after each other\n",
    "for word in f:\n",
    "    word = word.rstrip()\n",
    "    for i in range(len(word)-1):\n",
    "        letter = let2num(word[i])\n",
    "        letterAfter = let2num(word[i+1])\n",
    "        freq[letter,letterAfter] += 1\n",
    "f.close()\n",
    "\n",
    "for i in range(26):\n",
    "    rowSum = np.sum(freq[i])\n",
    "    prob[i] = freq[i]/rowSum\n",
    "\n",
    "freq = freq.T\n",
    "prob = prob.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: \n",
      "[ 1.    -0.419 -0.136 -0.136 -0.049 -0.049  0.08   0.08   0.115  0.086\n",
      "  0.086 -0.088  0.085  0.065  0.065 -0.024 -0.024  0.038 -0.033 -0.033\n",
      " -0.012 -0.012  0.01   0.01  -0.002  0.007]\n",
      "1-Eigenvector Scaled to Sum to 1\n",
      "[0.076 0.013 0.036 0.03  0.123 0.008 0.027 0.024 0.097 0.001 0.008 0.052\n",
      " 0.027 0.071 0.068 0.024 0.001 0.07  0.099 0.072 0.032 0.008 0.006 0.003\n",
      " 0.018 0.005]\n",
      "[0.077 0.018 0.04  0.033 0.113 0.012 0.028 0.025 0.091 0.002 0.009 0.052\n",
      " 0.029 0.067 0.067 0.03  0.002 0.07  0.096 0.066 0.033 0.009 0.007 0.003\n",
      " 0.016 0.005]\n",
      "They are indeed similar\n",
      "The probability that 'u' follows 'q': 0.9792560801144492\n",
      "Some words in which 'u' follows 'q': \n",
      "['absquatulate', 'absquatulated', 'absquatulates', 'absquatulating', 'acequia']\n"
     ]
    }
   ],
   "source": [
    "value, vector = np.linalg.eig(prob)\n",
    "print(\"Eigenvalues: \")\n",
    "print(np.real(value))\n",
    "#eigenvalue of 1 is at index 0\n",
    "\n",
    "print(\"1-Eigenvector Scaled to Sum to 1\")\n",
    "sum = np.sum(np.real(vector[:,0]))\n",
    "print(np.real(vector[:,0])/sum)\n",
    "\n",
    "\n",
    "#Question 3\n",
    "#As the limit approaches infinity, the term with the eigenvalue of 1 dominates, and so we expect\n",
    "#the probability ratios to mimic the one given by the 1-eigenvector. \n",
    "#Given no starting distribution, the probability of the next letter is just the frequency of each letter in\n",
    "#the word set; the more frequent that letter has appeared, the greater the chance it will be the next \n",
    "#letter. Similar to the weather example, since the transition matrix is column stochastic,\n",
    "#we are guaranteed a eigenvalue of 1, and the corresponding 1-eigenvector is a stationary distribution\n",
    "#and the stationary distribution is the long-term probability distributions.\n",
    "\n",
    "#Question 4\n",
    "#It is indeed the case that the entries of the eigenvector is close the the freq of the word set\n",
    "f = open('data/en.txt')\n",
    "totalFreqs = np.zeros(26)\n",
    "for word in f:\n",
    "    word = word.rstrip()\n",
    "    for char in word:\n",
    "        letter = let2num(char)\n",
    "        totalFreqs[letter] += 1\n",
    "print(totalFreqs/np.sum(totalFreqs))\n",
    "f.close()\n",
    "print(\"They are indeed similar\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"The probability that 'u' follows 'q': \" + str(prob[let2num(\"u\"),let2num(\"q\")]))\n",
    "q = []\n",
    "f = open('data/en.txt')\n",
    "for word in f:\n",
    "    if \"qu\" in word:\n",
    "        word = word.rstrip()\n",
    "        q.append(word)\n",
    "        if len(q) == 5:\n",
    "            break\n",
    "f.close()\n",
    "print(\"Some words in which 'u' follows 'q': \")\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sycoladegr\n",
      "posrarssuh\n",
      "dyataerior\n",
      "rueomlconl\n",
      "ghrdtlrhgr\n",
      "kllpdmatay\n",
      "feetaynlrt\n",
      "zhntcysrdf\n",
      "zniaensafi\n",
      "cserhotrco\n"
     ]
    }
   ],
   "source": [
    "def namegen(n):\n",
    "    #empty string to build the name with\n",
    "    name = \"\"\n",
    "    \n",
    "    #start with an equal chance of choosing any letter\n",
    "    v = np.ones(26)/26\n",
    "\n",
    "    for i in range(10):\n",
    "        name += chr(np.random.choice(26,p=v) + 97) #ASCII shift by 97 to get a valid letter\n",
    "        v = prob@v #get probability of next letter\n",
    "    return name\n",
    "\n",
    "for i in range(10):\n",
    "    print(namegen(np.random.randint(4,8)))\n",
    "\n",
    "#Most of them are not pronounceable because this implementation only considers one letter following\n",
    "#another and fails to consider entire syllable clusters or position in the name/word itself. As such,\n",
    "#we get some syllable clusters or syllable positions that are not permissible in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consider the previous two/three letters when deciding the letter after"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
